[google_credentials]
SERVICE_ACCOUNT_FILE_PATH = /path/to/key/service_acc_key.json

[delete_blobs]
TARGET_PROJECT = shc-price-rec-prod

[sears_buybox]
TARGET_PROJECT = shc-price-rec-prod
TARGET_TABLE = dp_spark_source_tbl.Sears_Buybox

[sears_static]
TARGET_PROJECT = shc-price-rec-prod
TARGET_TABLE = dp_spark_source_tbl.static_table_sears

[sears_static_copy]
SOURCE_PROJECT = shc-price-rec-prod
SOURCE_TABLE = dp_spark_source_tbl.static_table_sears
TARGET_PROJECT = shc-pricing-prod
TARGET_TABLE = static_tables.static__table_{YYYYMMDD}

[all_comp_all]
TARGET_PROJECT = shc-price-rec-prod
TARGET_TABLE = dp_spark_source_tbl.all_comp_all

[all_comp_all_copy]
SOURCE_PROJECT = shc-price-rec-prod
SOURCE_TABLE = dp_spark_source_tbl.all_comp_all
TARGET_PROJECT = shc-pricing-prod
TARGET_TABLE = comp_tables_partitioned.all_comp_all${YYYYMMDD}

[build_egg_and_upload_to_gcs]
TARGET_PROJECT = shc-price-rec-prod

[pyspark_dataproc]
ENVIRONMENT = prod
TARGET_PROJECT = shc-price-rec-prod
CLUSTER_NAME = airflow-dp-cluster-test
NUMBER_OF_WORKER_NODES_IN_CLUSTER = 6
NUMBER_OF_PRE_EMPTIBLE_WORKER_NODES_IN_CLUSTER = 8
MASTER_MACHINE_TYPE = n1-standard-8
MASTER_BOOT_DISK_SIZE = 200
WORKER_MACHINE_TYPE = n1-standard-8
WORKER_BOOT_DISK_SIZE = 200
REGION = us-central1
ZONE = us-central1-c
SUBNETWORK_URI = shc-default
IMAGE_VERSION = 1.5-debian10
METADATA_PIP_PACKAGES = numpy,pandas,google-cloud-bigquery,google-cloud-storage,google-cloud-core
INIT_ACTION_URIS = gs://goog-dataproc-initialization-actions-us-central1/python/pip-install.sh
IDLE_DELETE_TTL = 700
RETRIES = 1

[pyspark_job]
TARGET_PREFIX = dp_scheduler

[sears_run_summary]
TARGET_PROJECT = shc-price-rec-prod
TARGET_PREFIX = dp_scheduler

[export_FTP_sears]
SOURCE_PROJECT = shc-price-rec-prod
TARGET_PROJECT = shc-pricing-prod
TARGET_TABLE_NAME_TEMPLATE = FTP_tables_partitioned.FTP_sears_{rundate}_{run_id_str}
CREATE_GCS_LOG_PATH = YES
TARGET_GCS_LOG_PATH = gs://shc-pricing-prod-pricing-it/output_csv_files/{rundate}/sears_dp_price_{rundate}_{run_id_str}.csv
EXPORT_IF_BQ_IS_EMPTY = NO
TARGET_GCS_EXPORT_PATH = gs://pricing_files/sears_price_file/sears_dp_price_{rundate}_{run_id_str}.csv 

[export_rules_sears]
SOURCE_PROJECT = shc-price-rec-prod
TARGET_PROJECT = shc-pricing-prod
TARGET_TABLE_NAME_TEMPLATE = FTP_tables_partitioned.rule_sears_{rundate}_{run_id_str}
CREATE_GCS_LOG_PATH = YES
TARGET_GCS_LOG_PATH = gs://shc-pricing-prod-pricing-it/output_csv_files/{rundate}/rule_sears_{rundate}_{run_id_str}.csv 

[export_points_sears]
SOURCE_PROJECT = shc-price-rec-prod
TARGET_PROJECT = shc-pricing-prod
TARGET_TABLE_NAME_TEMPLATE = FTP_tables_partitioned.FTP_sears_points_{rundate}_{run_id_str}
CREATE_GCS_LOG_PATH = YES
TARGET_GCS_LOG_PATH = gs://shc-pricing-prod-pricing-it/output_csv_files/{rundate}/points_sears_{rundate}_{run_id_str}.csv 
EXPORT_IF_BQ_IS_EMPTY = NO 
TARGET_GCS_EXPORT_PATH = gs://pricing_files/points_back_offer_prod/points_sears_{rundate}_{run_id_str}.csv 

[export_min_comp_all]
TARGET_PROJECT = shc-pricing-prod
TARGET_TABLE_NAME_TEMPLATE = comp_tables_partitioned.min_comp_all${rundate}

[export_min_comp_MM]
TARGET_PROJECT = shc-pricing-prod
TARGET_TABLE_NAME_TEMPLATE = comp_tables_partitioned.min_comp_MM${rundate}

[loggers]
keys=root,dpRun,myLib

[handlers]
keys=consoleHandler

[formatters]
keys=simpleFormatter

[logger_root]
level=INFO
handlers=consoleHandler

[logger_dpRun]
level=DEBUG
handlers=consoleHandler
qualname=dpRun
propagate=0

[logger_myLib]
level=DEBUG
handlers=consoleHandler
qualname=myLib
propagate=0

[handler_consoleHandler]
class=StreamHandler
level=DEBUG
formatter=simpleFormatter
args=(sys.stdout,)

[formatter_simpleFormatter]
format=[%(asctime)s] {{%(filename)s:%(lineno)-3s}} %(levelname)-8s - %(funcName)10s(): %(message)s
datefmt=%Y-%m-%d %H:%M:%S

